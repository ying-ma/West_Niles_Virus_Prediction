{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from math import sin, cos, sqrt, atan2, radians\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from xgboost import XGBClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_coordinate(lat1,lon1,lat2,lon2):\n",
    "    # calculate the distance between 2 gps coordinate based on haver sin algorithm, resulting distance as km\n",
    "    R = 6373.0\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "\n",
    "    a = sin(dlat / 2)**2 + cos(lat1) * cos(lat2) * sin(dlon / 2)**2\n",
    "    c = 2 * atan2(sqrt(a), sqrt(1 - a))\n",
    "\n",
    "    return R * c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# relative humidity calculator (in percent)\n",
    "def relative_humidity(T_dry, T_wet, SP):\n",
    "    T_dry = (T_dry-32) * 5/9 # adjusting for temperature\n",
    "    T_wet = (T_wet-32) * 5/9\n",
    "    e_d = 6.112*np.exp(17.502*T_dry/(240.97+T_dry))\n",
    "    e_w = 6.112*np.exp(17.502*T_wet/(240.97+T_wet))\n",
    "    A = 0.00066*(1+0.00115*T_wet)\n",
    "    P = 33.8639*SP # convert inch of mercury to pasco\n",
    "    Hr = (e_w-A*P*(T_dry-T_wet))/e_d*100\n",
    "    return Hr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weather_delay(weather_in, N_delay):\n",
    "    '''delay the weather feature for N weeks. '''  \n",
    "        \n",
    "    weather_tmp = weather_in.copy(deep = True)  \n",
    "    \n",
    "    weather_tmp.Month = weather_tmp.Month+N_delay\n",
    "\n",
    "    col_name = [x+'_'+str(N_delay)+'w' for i,x in enumerate(list(weather_in.keys()))]\n",
    "    weather_tmp.columns = col_name\n",
    "    weather_tmp.columns.values[0:2]=('Year','Month')\n",
    "        \n",
    "    # handle missing rows\n",
    "    weather_tmp = weather_tmp.shift(N_delay)\n",
    "    for i in range(N_delay):\n",
    "        weather_tmp.iloc[i,:] = weather_tmp.iloc[N_delay,:]\n",
    "        weather_tmp.Month.iloc[i] = weather_tmp.Month.iloc[N_delay]-(N_delay-i)\n",
    "    \n",
    "    return weather_tmp  \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_species(X):    \n",
    "    X['Species'] = X['Species'].replace('CULEX PIPIENS/RESTUANS', 'P/R')\n",
    "    X['Species'] = X['Species'].replace('CULEX RESTUANS', 'R')\n",
    "    X['Species'] = X['Species'].replace('CULEX PIPIENS', 'P')\n",
    "    X['Species'] = X['Species'].replace('CULEX TERRITANS', 'Others')\n",
    "    X['Species'] = X['Species'].replace('CULEX SALINARIUS', 'Others')\n",
    "    X['Species'] = X['Species'].replace('CULEX TARSALIS', 'Others')\n",
    "    X['Species'] = X['Species'].replace('CULEX ERRATICUS', 'Others')\n",
    "    X['Species'] = X['Species'].replace('UNSPECIFIED CULEX', 'Others')\n",
    "    return X "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-processing function\n",
    "def preprocess(train, test, weather_data):\n",
    "    # create empty dataframe\n",
    "    X = pd.DataFrame()\n",
    "    \n",
    "    # temporal features\n",
    "    X['Month'] = [x.week for x in test.Date]\n",
    "    X['Year'] = [x.year for x in test.Date]\n",
    "    X['Day'] = [x.dayofyear for x in test.Date]\n",
    "    \n",
    "    # adding geographic coordinates\n",
    "    X['Latitude'] = test.Latitude\n",
    "    X['Longitude'] = test.Longitude\n",
    "    \n",
    "    # adding trap_id as one-hot encoding\n",
    "#     X['Trap_id'] = train.Trap.astype('category')\n",
    "#     X = pd.concat((X, pd.get_dummies(X['Trap_id'], drop_first=True, prefix='Trap')),axis=1)\n",
    "#     X = X.drop('Trap_id', axis = 1)\n",
    "    \n",
    "    # adding distance matrix\n",
    "    dist_mat = distance_matrix(train, test)\n",
    "    X['Trap_id'] = test.Trap.astype('category')\n",
    "    X = X.merge(dist_mat, left_on=['Trap_id','Latitude','Longitude'], right_on=['Trap','Latitude','Longitude'], how='left')\n",
    "    X = X.drop(['Trap','Trap_id'], axis = 1)\n",
    "    \n",
    "    # adding species\n",
    "    test = adjust_species(test)\n",
    "    X = pd.concat((X, pd.get_dummies(test['Species'], drop_first=True, prefix='Species')),axis=1)\n",
    "        \n",
    "    #X['AddressAccuracy'] = train.AddressAccuracy    \n",
    "    \n",
    "    # adding current weather info\n",
    "    X = X.merge(weather_data, on=['Year','Month'], how='left')\n",
    "    \n",
    "    # adding previous month info\n",
    "    N_month = 4\n",
    "    for i in range(1, N_month+1):\n",
    "         X = X.merge(weather_delay(weather_data,i), on=['Year','Month'], how='left')\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_matrix(target_train, target_test):\n",
    "    # create distance matrix between target_train and target_test\n",
    "    # target_test is observations (rows)\n",
    "    # target_train is features (columns)\n",
    "    \n",
    "    tmp_train  = target_train[['Date','Trap','Latitude','Longitude']].groupby(['Trap','Latitude','Longitude']).count().reset_index()\n",
    "    tmp_test = target_test[['Date','Trap','Latitude','Longitude']].groupby(['Trap','Latitude','Longitude']).count().reset_index()\n",
    "#    target_combined = pd.concat((tmp2, pd.get_dummies(tmp.Trap, prefix='Trap')),axis=1)\n",
    "\n",
    "    lamda = 1/3\n",
    "    dist_mat = np.zeros((tmp_test.shape[0], tmp_train.shape[0]))\n",
    "    \n",
    "    for i, trap_loc in enumerate(tmp_test.Trap):\n",
    "        lat1, lon1 = tmp_test[['Latitude','Longitude']].loc[i]\n",
    "        \n",
    "        for j, value in enumerate(tmp_train.Trap):        \n",
    "            lat2, lon2 = tmp_train[['Latitude','Longitude']].iloc[j]\n",
    "            dist = distance_coordinate(radians(lat1),radians(lon1),radians(lat2),radians(lon2))\n",
    "           # dist_mat[i,j]= dist\n",
    "            dist_mat[i,j]= 2/(1+np.exp(lamda*dist))\n",
    "    \n",
    "    target_combine = pd.concat((tmp_test,pd.DataFrame(data=dist_mat, columns = tmp_train.Trap)), axis = 1)\n",
    "    target_combine = target_combine.drop('Date', axis=1)\n",
    "    # adjusting for duplicated column names\n",
    "    target_combine.columns=pd.io.parsers.ParserBase({'names':target_combine.columns})._maybe_dedup_names(target_combine.columns)\n",
    "    return target_combine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "traps = pd.read_csv('../SparkBeyond/data/train.csv')\n",
    "weather = pd.read_csv('../SparkBeyond/data/weather.csv')\n",
    "traps_test = pd.read_csv('../SparkBeyond/data/test.csv')\n",
    "submission = pd.read_csv('../SparkBeyond/data/sampleSubmission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collapse records that are separated because the number of catched mosquitos exceed 50\n",
    "traps = traps.groupby(['Date', 'Trap', 'Species','Latitude','Longitude','AddressAccuracy','Block','Street']).sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-processing\n",
    "\n",
    "# get right format for date\n",
    "traps.Date = pd.to_datetime(traps.Date)\n",
    "traps_test.Date = pd.to_datetime(traps_test.Date)\n",
    "\n",
    "weather = weather.replace('M', np.NaN)\n",
    "weather = weather.replace('-', np.NaN)\n",
    "weather = weather.replace('T', np.NaN)\n",
    "weather = weather.replace(' T', np.NaN)\n",
    "weather = weather.replace('  T', np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep the information from station1\n",
    "\n",
    "weather_stn1 = weather[weather['Station']==1]\n",
    "weather_stn1 = weather_stn1.drop(['Station', 'Water1', 'Heat', 'Cool', 'CodeSum','SnowFall','Depth','Sunrise','Sunset'], axis = 1)\n",
    "weather_stn1.Date = pd.to_datetime(weather_stn1.Date)\n",
    "weather_stn1['Month'] = [x.week for x in weather_stn1.Date]\n",
    "weather_stn1['Year'] = [x.year for x in weather_stn1.Date]\n",
    "    \n",
    "weather_stn1 = weather_stn1.apply(pd.to_numeric).drop(['Date'], axis = 1).reset_index(drop = True)\n",
    "#weather_stn1 = weather_stn1.groupby(['Year','Month']).mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refine features\n",
    "# adding temperature difference\n",
    "weather_stn1['Tdif'] = weather_stn1.Tmax - weather_stn1.Tmin\n",
    "weather_stn1 = weather_stn1.drop(['Tmax'], axis =1)\n",
    "\n",
    "# adding relative humidity (100)\n",
    "weather_stn1['RH'] = [relative_humidity(weather_stn1.Tavg.loc[i],\n",
    "                                        weather_stn1.WetBulb.loc[i],\n",
    "                                        weather_stn1.StnPressure.loc[i]) \n",
    "                      for i,x in enumerate(weather_stn1.Tmin)]\n",
    "\n",
    "weather_stn1['ResultDir'] = [np.sin(radians(x)) for x in weather_stn1['ResultDir']]\n",
    "\n",
    "weather_stn1 = weather_stn1.groupby(['Year','Month']).mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = preprocess(traps, traps, weather_stn1)\n",
    "X_test = preprocess(traps, traps_test, weather_stn1)\n",
    "#X_train['Trap_T234'] =0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.apply(pd.to_numeric)\n",
    "X_test = X_test.apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjusting the column sequence\n",
    "X_train = X_train[list(X_test.keys())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating target\n",
    "y_train = (traps.WnvPresent>0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Training with XGB\n",
    "from xgboost import XGBClassifier\n",
    "xgb = XGBClassifier(n_estimators=100, learning_rate=0.125)\n",
    "xgb.fit(X_train, y_train)\n",
    "yhat = xgb.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training with Logistic\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lor = LogisticRegression(penalty='l1', C=100,)\n",
    "lor.fit(X_train, y_train)\n",
    "yhat = lor.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ying/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "# Generating submission results\n",
    "submission['WnvPresent'] = yhat[:,1]\n",
    "# adjusting Species from others to probability of zero\n",
    "submission.WnvPresent[adjust_species(traps_test).Species=='Others'] = 0\n",
    "\n",
    "submission.to_csv('submission_xgb_weather_delay_spatial.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
